# app/rag/document_loader.py

import logging
from pathlib import Path
from typing import List, Dict, Any, Optional
from langchain_core.documents import Document
from app.core.config import settings

logger = logging.getLogger(__name__)


class DocumentLoader:
    def __init__(self):
        # ÐŸÐ¾Ð»ÑƒÑ‡Ð°ÐµÐ¼ Ð¿Ð¾Ð´Ð´ÐµÑ€Ð¶Ð¸Ð²Ð°ÐµÐ¼Ñ‹Ðµ Ñ‚Ð¸Ð¿Ñ‹ Ð¸Ð· ÐºÐ¾Ð½Ñ„Ð¸Ð³ÑƒÑ€Ð°Ñ†Ð¸Ð¸
        self.supported_loaders = {
            ".pdf": self.load_pdf,
            ".docx": self.load_docx,
            ".txt": self.load_text,
            ".csv": self.load_csv,
            ".xlsx": self.load_excel,
            ".json": self.load_json,
            ".md": self.load_markdown,
        }
        logger.info("DocumentLoader initialized")

    async def load_file(self, filepath: str, metadata: Optional[Dict[str, Any]] = None) -> List[Document]:
        path = Path(filepath)
        if not path.exists():
            raise FileNotFoundError(f"File not found: {filepath}")

        # Ð˜Ð¡ÐŸÐ ÐÐ’Ð›Ð•ÐÐ˜Ð• 1: ÐŸÑ€Ð¾Ð²ÐµÑ€ÐºÐ° Ñ€Ð°Ð·Ð¼ÐµÑ€Ð° Ñ„Ð°Ð¹Ð»Ð° Ð”Ðž Ð¾Ð±Ñ€Ð°Ð±Ð¾Ñ‚ÐºÐ¸
        file_size_mb = path.stat().st_size / (1024 * 1024)
        if file_size_mb > settings.MAX_FILESIZE_MB:
            raise ValueError(
                f"File {path.name} exceeds max allowed size: "
                f"{file_size_mb:.2f} MB > {settings.MAX_FILESIZE_MB} MB"
            )

        ext = path.suffix.lower()
        if not settings.is_file_supported(filepath):
            raise ValueError(f"Filetype {ext} not supported")

        logger.info(f"ðŸ“‚ Loading file: {path.name} ({file_size_mb:.2f} MB)")
        return await self.supported_loaders[ext](filepath, metadata)

    async def load_pdf(self, filepath: str, metadata: Optional[Dict[str, Any]]) -> List[Document]:
        from langchain_community.document_loaders import PyPDFLoader
        loader = PyPDFLoader(filepath)
        return loader.load()

    async def load_docx(self, filepath: str, metadata: Optional[Dict[str, Any]]) -> List[Document]:
        try:
            from langchain_community.document_loaders import Docx2txtLoader
            loader = Docx2txtLoader(filepath)
            return loader.load()
        except ImportError:
            raise ImportError("docx2txt required. Install: pip install docx2txt")

    async def load_text(self, filepath: str, metadata: Optional[Dict[str, Any]]) -> List[Document]:
        from langchain_community.document_loaders import TextLoader
        loader = TextLoader(filepath, encoding='utf-8')
        return loader.load()

    async def load_csv(self, filepath: str, metadata: Optional[Dict[str, Any]]) -> List[Document]:
        from langchain_community.document_loaders import CSVLoader
        loader = CSVLoader(filepath, encoding='utf-8')
        return loader.load()

    async def load_excel(self, filepath: str, metadata: Optional[Dict[str, Any]]) -> List[Document]:
        """
        Ð˜Ð¡ÐŸÐ ÐÐ’Ð›Ð•ÐÐž: ÐžÐ¿Ñ‚Ð¸Ð¼Ð¸Ð·Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð½Ð°Ñ Ð·Ð°Ð³Ñ€ÑƒÐ·ÐºÐ° Excel Ñ Ð¼Ð¸Ð½Ð¸Ð¼Ð°Ð»ÑŒÐ½Ñ‹Ð¼ ÐºÐ¾Ð»Ð¸Ñ‡ÐµÑÑ‚Ð²Ð¾Ð¼ Ñ‡Ð°Ð½ÐºÐ¾Ð²
        - ÐžÐ±ÑŠÐµÐ´Ð¸Ð½ÑÐµÑ‚ Ð²ÑÐµ Ð»Ð¸ÑÑ‚Ñ‹ Ð² Ð¾Ð´Ð¸Ð½ Ð´Ð¾ÐºÑƒÐ¼ÐµÐ½Ñ‚
        - Ð¡Ð¾Ñ…Ñ€Ð°Ð½ÑÐµÑ‚ ÑÑ‚Ñ€ÑƒÐºÑ‚ÑƒÑ€Ñƒ Ñ‚Ð°Ð±Ð»Ð¸Ñ†Ñ‹
        - Ð˜Ð·Ð±ÐµÐ³Ð°ÐµÑ‚ Ð¸Ð·Ð»Ð¸ÑˆÐ½ÐµÐ¹ Ñ„Ñ€Ð°Ð³Ð¼ÐµÐ½Ñ‚Ð°Ñ†Ð¸Ð¸
        """
        try:
            import pandas as pd

            excel_file = pd.ExcelFile(filepath)
            all_sheets_content = []

            logger.info(f"ðŸ“Š Processing Excel file with {len(excel_file.sheet_names)} sheet(s)")

            for sheet_name in excel_file.sheet_names:
                try:
                    df = pd.read_excel(filepath, sheet_name=sheet_name)

                    # ÐŸÑ€Ð¾Ð¿ÑƒÑÐºÐ°ÐµÐ¼ Ð¿ÑƒÑÑ‚Ñ‹Ðµ Ð»Ð¸ÑÑ‚Ñ‹
                    if df.empty:
                        logger.warning(f"âš ï¸ Sheet '{sheet_name}' is empty, skipping")
                        continue

                    # Ð¤Ð¾Ñ€Ð¼Ð¸Ñ€ÑƒÐµÐ¼ ÑÑ‚Ñ€ÑƒÐºÑ‚ÑƒÑ€Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð½Ñ‹Ð¹ Ñ‚ÐµÐºÑÑ‚ Ð´Ð»Ñ Ð»Ð¸ÑÑ‚Ð°
                    sheet_content = []
                    sheet_content.append(f"\n{'=' * 60}")
                    sheet_content.append(f"Ð›Ð˜Ð¡Ð¢: {sheet_name}")
                    sheet_content.append(f"{'=' * 60}")

                    # Ð”Ð¾Ð±Ð°Ð²Ð»ÑÐµÐ¼ Ð·Ð°Ð³Ð¾Ð»Ð¾Ð²ÐºÐ¸
                    headers = df.columns.tolist()
                    sheet_content.append(f"\nÐšÐ¾Ð»Ð¾Ð½ÐºÐ¸: {', '.join(str(h) for h in headers)}")
                    sheet_content.append(f"ÐšÐ¾Ð»Ð¸Ñ‡ÐµÑÑ‚Ð²Ð¾ ÑÑ‚Ñ€Ð¾Ðº: {len(df)}\n")

                    # Ð˜Ð¡ÐŸÐ ÐÐ’Ð›Ð•ÐÐ˜Ð• 2: ÐžÐ¿Ñ‚Ð¸Ð¼Ð¸Ð·Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð½Ð¾Ðµ Ñ„Ð¾Ñ€Ð¼Ð°Ñ‚Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð¸Ðµ ÑÑ‚Ñ€Ð¾Ðº
                    # Ð“Ñ€ÑƒÐ¿Ð¿Ð¸Ñ€ÑƒÐµÐ¼ Ð´Ð°Ð½Ð½Ñ‹Ðµ Ð² Ð±Ð»Ð¾ÐºÐ¸ Ð¿Ð¾ 10 ÑÑ‚Ñ€Ð¾Ðº Ð´Ð»Ñ ÑƒÐ¼ÐµÐ½ÑŒÑˆÐµÐ½Ð¸Ñ Ñ„Ñ€Ð°Ð³Ð¼ÐµÐ½Ñ‚Ð°Ñ†Ð¸Ð¸
                    rows_per_block = 10
                    for block_start in range(0, len(df), rows_per_block):
                        block_end = min(block_start + rows_per_block, len(df))
                        sheet_content.append(f"\n--- Ð¡Ñ‚Ñ€Ð¾ÐºÐ¸ {block_start + 1}-{block_end} ---")

                        for idx in range(block_start, block_end):
                            row = df.iloc[idx]
                            row_parts = []
                            for col in df.columns:
                                value = row[col]
                                if pd.notna(value):
                                    # ÐžÐ±Ñ€ÐµÐ·Ð°ÐµÐ¼ ÑÐ»Ð¸ÑˆÐºÐ¾Ð¼ Ð´Ð»Ð¸Ð½Ð½Ñ‹Ðµ Ð·Ð½Ð°Ñ‡ÐµÐ½Ð¸Ñ
                                    str_value = str(value)
                                    if len(str_value) > 200:
                                        str_value = str_value[:200] + "..."
                                    row_parts.append(f"{col}: {str_value}")

                            if row_parts:
                                sheet_content.append(f"Ð¡Ñ‚Ñ€Ð¾ÐºÐ° {idx + 1}: {' | '.join(row_parts)}")

                    all_sheets_content.append("\n".join(sheet_content))
                    logger.info(f"âœ… Processed sheet '{sheet_name}': {len(df)} rows, {len(df.columns)} columns")

                except Exception as e:
                    logger.warning(f"âš ï¸ Error reading sheet '{sheet_name}': {str(e)}")
                    continue

            if not all_sheets_content:
                raise ValueError(f"No readable data found in Excel file: {filepath}")

            # Ð˜Ð¡ÐŸÐ ÐÐ’Ð›Ð•ÐÐ˜Ð• 3: Ð¡Ð¾Ð·Ð´Ð°ÐµÐ¼ ÐžÐ”Ð˜Ð Ð´Ð¾ÐºÑƒÐ¼ÐµÐ½Ñ‚ Ð´Ð»Ñ Ð²ÑÐµÐ³Ð¾ Ñ„Ð°Ð¹Ð»Ð°
            # Ð­Ñ‚Ð¾ Ð¿Ñ€ÐµÐ´Ð¾Ñ‚Ð²Ñ€Ð°Ñ‚Ð¸Ñ‚ Ð¸Ð·Ð»Ð¸ÑˆÐ½ÐµÐµ Ð´Ñ€Ð¾Ð±Ð»ÐµÐ½Ð¸Ðµ Ð½Ð° Ñ‡Ð°Ð½ÐºÐ¸
            combined_content = "\n\n".join(all_sheets_content)

            doc_metadata = {
                "source": filepath,
                "file_type": "xlsx",
                "sheet_count": len(excel_file.sheet_names),
                "total_content_length": len(combined_content),
            }

            if metadata:
                doc_metadata.update(metadata)

            document = Document(
                page_content=combined_content,
                metadata=doc_metadata
            )

            logger.info(
                f"âœ… Excel loaded as single document: "
                f"{len(excel_file.sheet_names)} sheets, "
                f"{len(combined_content)} chars"
            )

            return [document]

        except ImportError:
            logger.error("pandas and openpyxl are required for Excel file loading")
            raise ImportError("Please install: pip install pandas openpyxl")
        except Exception as e:
            logger.error(f"âŒ Error loading Excel file {filepath}: {str(e)}")
            raise

    async def load_json(self, filepath: str, metadata: Optional[Dict[str, Any]]) -> List[Document]:
        from langchain_community.document_loaders import JSONLoader
        loader = JSONLoader(filepath, jq_schema='.', text_content=False)
        return loader.load()

    async def load_markdown(self, filepath: str, metadata: Optional[Dict[str, Any]]) -> List[Document]:
        from langchain_community.document_loaders import UnstructuredMarkdownLoader
        loader = UnstructuredMarkdownLoader(filepath)
        return loader.load()
