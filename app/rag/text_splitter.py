# app/rag/text_splitter.py
import logging
from typing import List, Dict, Any
from langchain_core.documents import Document
from langchain_text_splitters import RecursiveCharacterTextSplitter
from app.core.config import settings

logger = logging.getLogger(__name__)

MIN_CHUNK_SIZE = 50
DEFAULT_CHUNK_SIZE = getattr(settings, "CHUNK_SIZE", 2000) or 2000  # –ò–°–ü–†–ê–í–õ–ï–ù–ò–ï: —É–≤–µ–ª–∏—á–µ–Ω–æ —Å 1000 –¥–æ 2000
DEFAULT_CHUNK_OVERLAP = getattr(settings, "CHUNK_OVERLAP", 400) or 400  # –ò–°–ü–†–ê–í–õ–ï–ù–ò–ï: —É–≤–µ–ª–∏—á–µ–Ω–æ —Å 200 –¥–æ 400


class SmartTextSplitter:
    def __init__(
            self,
            chunk_size: int = None,
            chunk_overlap: int = None,
            separators: List[str] = None
    ):
        raw_chunk_size = chunk_size if chunk_size is not None else DEFAULT_CHUNK_SIZE
        raw_chunk_overlap = chunk_overlap if chunk_overlap is not None else DEFAULT_CHUNK_OVERLAP

        try:
            raw_chunk_size = int(raw_chunk_size)
        except Exception:
            logger.warning(f"chunk_size={raw_chunk_size} is not int, fallback to {DEFAULT_CHUNK_SIZE}")
            raw_chunk_size = DEFAULT_CHUNK_SIZE

        if raw_chunk_size < MIN_CHUNK_SIZE:
            logger.warning(f"chunk_size={raw_chunk_size} < {MIN_CHUNK_SIZE}, bumping to {MIN_CHUNK_SIZE}")
            raw_chunk_size = MIN_CHUNK_SIZE

        try:
            raw_chunk_overlap = int(raw_chunk_overlap)
        except Exception:
            logger.warning(f"chunk_overlap={raw_chunk_overlap} is not int, fallback to {DEFAULT_CHUNK_OVERLAP}")
            raw_chunk_overlap = DEFAULT_CHUNK_OVERLAP

        if raw_chunk_overlap >= raw_chunk_size:
            adjusted = max(0, raw_chunk_size // 4)
            logger.warning(
                f"chunk_overlap={raw_chunk_overlap} >= chunk_size={raw_chunk_size}, "
                f"reducing overlap to {adjusted}"
            )
            raw_chunk_overlap = adjusted

        self.chunk_size = raw_chunk_size
        self.chunk_overlap = raw_chunk_overlap
        self.separators = separators or ["\n\n", "\n", ". ", " ", ""]

        self.text_splitter = RecursiveCharacterTextSplitter(
            chunk_size=self.chunk_size,
            chunk_overlap=self.chunk_overlap,
            separators=self.separators,
            length_function=len,
            is_separator_regex=False
        )

        logger.info(
            f"‚úÖ SmartTextSplitter initialized: "
            f"chunk_size={self.chunk_size}, overlap={self.chunk_overlap}"
        )

    def split_text(self, text: str) -> List[str]:
        """–†–∞–∑–±–∏—Ç—å —Ç–µ–∫—Å—Ç –Ω–∞ chunks"""
        try:
            if not text or not text.strip():
                logger.warning("‚ö†Ô∏è Empty text provided for splitting")
                return []

            logger.info(f"üî™ Splitting text ({len(text)} chars)...")
            chunks = self.text_splitter.split_text(text)
            logger.info(f"‚úÖ Text split into {len(chunks)} chunks")
            return chunks

        except Exception as e:
            logger.error(f"‚ùå Error splitting text: {e}")
            raise

    def split_documents(self, documents: List[Document]) -> List[Document]:
        """
        –ò–°–ü–†–ê–í–õ–ï–ù–û: –†–∞–∑–±–∏—Ç—å —Å–ø–∏—Å–æ–∫ Document –æ–±—ä–µ–∫—Ç–æ–≤ —Å —É—á–µ—Ç–æ–º —Ç–∏–ø–∞ —Ñ–∞–π–ª–∞
        –î–ª—è Excel —Ñ–∞–π–ª–æ–≤ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è —Å–ø–µ—Ü–∏–∞–ª—å–Ω–∞—è –ª–æ–≥–∏–∫–∞
        """
        try:
            if not documents:
                logger.warning("‚ö†Ô∏è Empty documents list provided")
                return []

            logger.info(f"üî™ Splitting {len(documents)} documents...")
            all_chunks = []

            for doc_idx, doc in enumerate(documents):
                file_type = doc.metadata.get('file_type', '')

                # –ò–°–ü–†–ê–í–õ–ï–ù–ò–ï 4: –°–ø–µ—Ü–∏–∞–ª—å–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ –¥–ª—è Excel
                if file_type in ['xlsx', 'xls', 'csv']:
                    logger.info(f"üìä Using optimized splitting for {file_type} file")
                    # –î–ª—è —Ç–∞–±–ª–∏—á–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö –∏—Å–ø–æ–ª—å–∑—É–µ–º —É–≤–µ–ª–∏—á–µ–Ω–Ω—ã–π chunk_size
                    excel_splitter = RecursiveCharacterTextSplitter(
                        chunk_size=self.chunk_size * 3,  # –£–≤–µ–ª–∏—á–∏–≤–∞–µ–º –≤ 3 —Ä–∞–∑–∞
                        chunk_overlap=self.chunk_overlap,
                        separators=["\n===", "\n---", "\n\n", "\n"],  # –†–∞–∑–±–∏–≤–∞–µ–º –ø–æ –ª–æ–≥–∏—á–µ—Å–∫–∏–º –±–ª–æ–∫–∞–º
                        length_function=len
                    )
                    text_chunks = excel_splitter.split_text(doc.page_content)
                else:
                    # –°—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–∞—è —Ä–∞–∑–±–∏–≤–∫–∞ –¥–ª—è –¥—Ä—É–≥–∏—Ö —Ç–∏–ø–æ–≤
                    text_chunks = self.text_splitter.split_text(doc.page_content)

                # –°–æ–∑–¥–∞—Ç—å Document –æ–±—ä–µ–∫—Ç—ã –¥–ª—è –∫–∞–∂–¥–æ–≥–æ chunk
                for chunk_idx, chunk_text in enumerate(text_chunks):
                    metadata = doc.metadata.copy()
                    metadata.update({
                        'chunk_index': chunk_idx,
                        'total_chunks': len(text_chunks),
                        'doc_index': doc_idx,
                        'chunk_size': len(chunk_text)
                    })

                    chunk_doc = Document(
                        page_content=chunk_text,
                        metadata=metadata
                    )
                    all_chunks.append(chunk_doc)

            logger.info(f"‚úÖ Created {len(all_chunks)} document chunks")
            return all_chunks

        except Exception as e:
            logger.error(f"‚ùå Error splitting documents: {e}")
            raise

    def create_documents_from_text(
            self,
            text: str,
            metadata: Dict[str, Any] = None
    ) -> List[Document]:
        """–°–æ–∑–¥–∞—Ç—å —Å–ø–∏—Å–æ–∫ Document –æ–±—ä–µ–∫—Ç–æ–≤ –∏–∑ —Ç–µ–∫—Å—Ç–∞ —Å –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–º–∏"""
        try:
            if not text or not text.strip():
                logger.warning("‚ö†Ô∏è Empty text provided")
                return []

            metadata = metadata or {}
            logger.info(f"üìÑ Creating documents from text ({len(text)} chars)...")

            chunks = self.split_text(text)

            documents = []
            for idx, chunk in enumerate(chunks):
                doc_metadata = metadata.copy()
                doc_metadata.update({
                    'chunk_index': idx,
                    'total_chunks': len(chunks),
                    'chunk_size': len(chunk)
                })

                doc = Document(
                    page_content=chunk,
                    metadata=doc_metadata
                )
                documents.append(doc)

            logger.info(f"‚úÖ Created {len(documents)} documents")
            return documents

        except Exception as e:
            logger.error(f"‚ùå Error creating documents: {e}")
            raise

    def split_by_file_type(
            self,
            text: str,
            file_type: str,
            metadata: Dict[str, Any] = None
    ) -> List[Document]:
        """
        –ò–°–ü–†–ê–í–õ–ï–ù–û: –†–∞–∑–±–∏—Ç—å —Ç–µ–∫—Å—Ç —Å —É—á–µ—Ç–æ–º —Ç–∏–ø–∞ —Ñ–∞–π–ª–∞
        """
        try:
            metadata = metadata or {}
            metadata['file_type'] = file_type

            # –ò–°–ü–†–ê–í–õ–ï–ù–ò–ï 5: –£–ª—É—á—à–µ–Ω–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ –¥–ª—è —Ä–∞–∑–Ω—ã—Ö —Ç–∏–ø–æ–≤
            if file_type in ['csv', 'xlsx', 'xls']:
                # –î–ª—è —Ç–∞–±–ª–∏—á–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö - –∑–Ω–∞—á–∏—Ç–µ–ª—å–Ω–æ –±–æ–ª—å—à–∏–π chunk size
                splitter = RecursiveCharacterTextSplitter(
                    chunk_size=self.chunk_size * 3,  # –£–≤–µ–ª–∏—á–µ–Ω–æ —Å *2 –¥–æ *3
                    chunk_overlap=self.chunk_overlap,
                    separators=["\n===", "\n---", "\n\n", "\n"],
                    length_function=len
                )
                chunks = splitter.split_text(text)

            elif file_type == 'json':
                splitter = RecursiveCharacterTextSplitter(
                    chunk_size=self.chunk_size,
                    chunk_overlap=self.chunk_overlap,
                    separators=["\n\n", "\n", ",", " "],
                    length_function=len
                )
                chunks = splitter.split_text(text)

            elif file_type == 'md':
                splitter = RecursiveCharacterTextSplitter(
                    chunk_size=self.chunk_size,
                    chunk_overlap=self.chunk_overlap,
                    separators=["\n## ", "\n### ", "\n\n", "\n", ". ", " "],
                    length_function=len
                )
                chunks = splitter.split_text(text)

            else:
                chunks = self.split_text(text)

            documents = []
            for idx, chunk in enumerate(chunks):
                doc_metadata = metadata.copy()
                doc_metadata.update({
                    'chunk_index': idx,
                    'total_chunks': len(chunks),
                    'chunk_size': len(chunk)
                })

                doc = Document(
                    page_content=chunk,
                    metadata=doc_metadata
                )
                documents.append(doc)

            logger.info(
                f"‚úÖ Split {file_type} file into {len(documents)} chunks "
                f"(avg size: {sum(len(c) for c in chunks) // len(chunks) if chunks else 0})"
            )
            return documents

        except Exception as e:
            logger.error(f"‚ùå Error splitting by file type: {e}")
            raise

    def get_chunk_stats(self, documents: List[Document]) -> Dict[str, Any]:
        """–ü–æ–ª—É—á–∏—Ç—å —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –ø–æ chunks"""
        if not documents:
            return {
                'total_chunks': 0,
                'avg_chunk_size': 0,
                'min_chunk_size': 0,
                'max_chunk_size': 0,
                'total_size': 0
            }

        chunk_sizes = [len(doc.page_content) for doc in documents]

        stats = {
            'total_chunks': len(documents),
            'avg_chunk_size': sum(chunk_sizes) // len(chunk_sizes),
            'min_chunk_size': min(chunk_sizes),
            'max_chunk_size': max(chunk_sizes),
            'total_size': sum(chunk_sizes),
            'overlap_ratio': self.chunk_overlap / self.chunk_size
        }

        logger.info(f"üìä Chunk statistics: {stats}")
        return stats
