# LLaMA Service

AI-powered chat service with RAG support.

## ğŸ“‹ Requirements

- Python 3.10+
- PostgreSQL 14+
- Ollama (for local LLM)

## ğŸš€ Quick Start

### 1. Install dependencies

```bash
pip install -r requirements.txt
```

### 2. Setup environment

Copy `.env.example` to `.env` and configure:

```bash
DATABASE_URL=postgresql+asyncpg://user:password@localhost/llama_db
JWT_SECRET_KEY=your-secret-key-change-this
EMBEDDINGS_BASEURL=http://localhost:11434
```

### 3. Initialize database

```bash
# Create tables
python scripts/init_db.py

# Create admin user
python scripts/create_admin.py
```

### 4. Run server

```bash
uvicorn app.main:app --reload --host 0.0.0.0 --port 8000
```

## ğŸ“š API Documentation

After starting, visit:
- Swagger UI: http://localhost:8000/docs
- ReDoc: http://localhost:8000/redoc

## ğŸ—ï¸ Project Structure

```
app/
â”œâ”€â”€ api/v1/         # API endpoints
â”œâ”€â”€ core/           # Core configuration
â”œâ”€â”€ crud/           # Database operations
â”œâ”€â”€ db/             # Database models
â”œâ”€â”€ schemas/        # Pydantic schemas
â”œâ”€â”€ services/       # Business logic
â””â”€â”€ rag/            # RAG components
```

## ğŸ”‘ Default Admin

- Username: `admin`
- Password: `admin123456`

âš ï¸ **Change password after first login!**


## ğŸ“ License

MIT
