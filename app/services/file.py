"""
File Processing Service
–°–µ—Ä–≤–∏—Å –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Ñ–∞–π–ª–æ–≤ –∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤
"""
import asyncio
from pathlib import Path
from uuid import UUID
import logging
from sqlalchemy import select

from app.db.session import AsyncSessionLocal
from app.crud import crud_file
from app.rag.document_loader import DocumentLoader
from app.rag.text_splitter import SmartTextSplitter
from app.rag.embeddings import EmbeddingsManager
from app.rag.vector_store import VectorStoreManager
from app.core.config import settings
from app.db.models.conversation_file import ConversationFile

logger = logging.getLogger(__name__)

document_loader = DocumentLoader()
text_splitter = SmartTextSplitter(
    chunk_size=settings.CHUNK_SIZE,
    chunk_overlap=settings.CHUNK_OVERLAP
)
vector_store = VectorStoreManager()


async def process_file_async(
        file_id: UUID,
        file_path: Path,
        embedding_mode: str = "local",
        embedding_model: str = None
) -> None:
    """
    –ó–∞–ø—É—Å—Ç–∏—Ç—å –∞—Å–∏–Ω—Ö—Ä–æ–Ω–Ω—É—é –æ–±—Ä–∞–±–æ—Ç–∫—É —Ñ–∞–π–ª–∞

    Args:
        file_id: ID —Ñ–∞–π–ª–∞
        file_path: –ü—É—Ç—å –∫ —Ñ–∞–π–ª—É
        embedding_mode: –†–µ–∂–∏–º –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤ ('local', 'aihub', 'openai')
        embedding_model: –ú–æ–¥–µ–ª—å –¥–ª—è —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤ (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
    """
    asyncio.create_task(_process_file(file_id, file_path, embedding_mode, embedding_model))


async def _process_file(
        file_id: UUID,
        file_path: Path,
        embedding_mode: str = "local",
        embedding_model: str = None
) -> None:
    """
    –û–±—Ä–∞–±–æ—Ç–∫–∞ —Ñ–∞–π–ª–∞: –∑–∞–≥—Ä—É–∑–∫–∞, —Ä–∞–∑–±–∏–µ–Ω–∏–µ –Ω–∞ —á–∞–Ω–∫–∏, –≥–µ–Ω–µ—Ä–∞—Ü–∏—è —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤

    Args:
        file_id: ID —Ñ–∞–π–ª–∞
        file_path: –ü—É—Ç—å –∫ —Ñ–∞–π–ª—É
        embedding_mode: –†–µ–∂–∏–º –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤ ('local', 'aihub', 'openai')
        embedding_model: –ú–æ–¥–µ–ª—å –¥–ª—è —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤ (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
    """
    async with AsyncSessionLocal() as db:
        try:
            logger.info(f"üîÑ Starting file processing: {file_id}, mode: {embedding_mode}")

            await crud_file.update_processing_status(
                db,
                file_id=file_id,
                status="processing"
            )

            # –ü–æ–ª—É—á–∞–µ–º conversation_id –î–û –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Ñ–∞–π–ª–∞
            query = select(ConversationFile.conversation_id).where(
                ConversationFile.file_id == file_id
            )
            result = await db.execute(query)
            conversation_ids = result.scalars().all()

            conversation_id = None
            if conversation_ids:
                conversation_id = str(conversation_ids[0])
                logger.info(f"üìé File {file_id} associated with conversation {conversation_id}")
            else:
                logger.warning(f"‚ö†Ô∏è File {file_id} not associated with any conversation")

            # –ó–∞–≥—Ä—É–∑–∫–∞ –¥–æ–∫—É–º–µ–Ω—Ç–∞
            logger.info(f"üìÇ Loading file: {file_path}")
            documents = await document_loader.load_file(str(file_path))

            if not documents:
                raise ValueError("No documents loaded from file")

            logger.info(f"‚úÖ Loaded {len(documents)} document(s)")

            # –†–∞–∑–±–∏–µ–Ω–∏–µ –Ω–∞ —á–∞–Ω–∫–∏
            chunk_docs = text_splitter.split_documents(documents)
            if not chunk_docs:
                raise ValueError("No chunks created from documents")

            logger.info(f"‚úÖ Created {len(chunk_docs)} chunks")

            # –ü–æ–ª—É—á–∞–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ —Ñ–∞–π–ª–µ
            file_record = await crud_file.get(db, id=file_id)
            if not file_record:
                raise ValueError(f"File record not found: {file_id}")

            # –°–æ–∑–¥–∞–µ–º EmbeddingsManager —Å –Ω—É–∂–Ω—ã–º —Ä–µ–∂–∏–º–æ–º
            embedding_service = EmbeddingsManager(
                mode=embedding_mode,
                model=embedding_model
            )

            logger.info(f"üßÆ Generating embeddings using {embedding_mode} and storing in vector DB...")

            # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º —ç–º–±–µ–¥–¥–∏–Ω–≥–∏ –¥–ª—è –≤—Å–µ—Ö —á–∞–Ω–∫–æ–≤
            for idx, chunk_doc in enumerate(chunk_docs):
                chunk_text = chunk_doc.page_content

                # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º —ç–º–±–µ–¥–¥–∏–Ω–≥ (–∏—Å–ø–æ–ª—å–∑—É–µ–º –∞—Å–∏–Ω—Ö—Ä–æ–Ω–Ω—ã–π –º–µ—Ç–æ–¥)
                embeddings = await embedding_service.embedd_documents_async([chunk_text])

                if embeddings and len(embeddings) > 0:
                    embedding = embeddings[0]

                    # –ú–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ –¥–ª—è –≤–µ–∫—Ç–æ—Ä–Ω–æ–π –ë–î
                    metadata = {
                        "file_id": str(file_id),
                        "user_id": str(file_record.user_id),
                        "conversation_id": conversation_id,  # –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∏ –≤–∞–∂–Ω–æ!
                        "chunk_index": idx,
                        "total_chunks": len(chunk_docs),
                        "filename": file_record.original_filename,
                        "file_type": file_record.file_type,
                        "content": chunk_text,
                        "embedding_mode": embedding_mode,  # –î–æ–±–∞–≤–ª—è–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ —Ä–µ–∂–∏–º–µ
                        "embedding_model": embedding_model or "default"
                    }

                    # –î–æ–±–∞–≤–ª—è–µ–º –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ –∏–∑ chunk_doc –µ—Å–ª–∏ –µ—Å—Ç—å
                    if chunk_doc.metadata:
                        metadata.update(chunk_doc.metadata)

                    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ –≤–µ–∫—Ç–æ—Ä–Ω—É—é –ë–î
                    vector_store.add_document(
                        doc_id=f"{file_id}_{idx}",
                        embedding=embedding,
                        metadata=metadata
                    )
                else:
                    logger.warning(f"‚ö†Ô∏è No embedding generated for chunk {idx}")

            logger.info(f"‚úÖ All chunks stored in vector DB")

            # –û–±–Ω–æ–≤–ª—è–µ–º —Å—Ç–∞—Ç—É—Å —Ñ–∞–π–ª–∞
            await crud_file.update_processing_status(
                db,
                file_id=file_id,
                status="completed",
                chunks_count=len(chunk_docs),
                embedding_model=f"{embedding_mode}:{embedding_model or 'default'}"
            )

            logger.info(f"‚úÖ File {file_id} processed successfully: {len(chunk_docs)} chunks")

        except Exception as e:
            logger.error(
                f"‚ùå File processing failed for {file_id}: {type(e).__name__}: {str(e)}",
                exc_info=True
            )
            await crud_file.update_processing_status(
                db,
                file_id=file_id,
                status="failed"
            )
