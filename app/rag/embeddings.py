"""
Embeddings Manager
–ú–µ–Ω–µ–¥–∂–µ—Ä –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤ —á–µ—Ä–µ–∑ —Ä–∞–∑–ª–∏—á–Ω—ã–µ –ø—Ä–æ–≤–∞–π–¥–µ—Ä—ã
"""
import logging
from typing import List, Optional

from app.core.config import settings
from app.services.llm.manager import llm_manager

logger = logging.getLogger(__name__)


class EmbeddingsManager:
    """
    –ú–µ–Ω–µ–¥–∂–µ—Ä —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤ —Å –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π —Ä–∞–∑–ª–∏—á–Ω—ã—Ö –ø—Ä–æ–≤–∞–π–¥–µ—Ä–æ–≤
    –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç: local (Ollama), corporate/aihub (AI HUB)
    """

    # –ú–∞–ø–ø–∏–Ω–≥ —Ä–µ–∂–∏–º–æ–≤ –Ω–∞ —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç–∏ —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤
    DEFAULT_DIMENSIONS = {
        "local": 4096,  # –ü–æ —É–º–æ–ª—á–∞–Ω–∏—é –¥–ª—è Ollama
        "aihub": 1024,  # arctic –º–æ–¥–µ–ª—å
    }

    def __init__(
        self,
        mode: str = "local",
        model: Optional[str] = None,
        ollama_url: Optional[str] = None,
        hub_url: Optional[str] = None,
        keycloak_token: Optional[str] = None,
        system_user: Optional[str] = None
    ):
        """
        –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –º–µ–Ω–µ–¥–∂–µ—Ä–∞ —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤

        Args:
            mode: –†–µ–∂–∏–º —Ä–∞–±–æ—Ç—ã ('local' –∏–ª–∏ 'corporate')
            model: –ú–æ–¥–µ–ª—å –¥–ª—è —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤ (–µ—Å–ª–∏ –Ω–µ —É–∫–∞–∑–∞–Ω–∞, –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –∏–∑ –Ω–∞—Å—Ç—Ä–æ–µ–∫)
            ollama_url: URL Ollama (–¥–ª—è –æ–±—Ä–∞—Ç–Ω–æ–π —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏)
            hub_url: URL HUB (–¥–ª—è –æ–±—Ä–∞—Ç–Ω–æ–π —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏)
            keycloak_token: –¢–æ–∫–µ–Ω Keycloak (–¥–ª—è –æ–±—Ä–∞—Ç–Ω–æ–π —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏)
            system_user: System user (–¥–ª—è –æ–±—Ä–∞—Ç–Ω–æ–π —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏)
        """
        # –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è —Ä–µ–∂–∏–º–∞: corporate -> aihub (–¥–ª—è –≤–Ω—É—Ç—Ä–µ–Ω–Ω–µ–≥–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è)
        self.mode = "aihub" if mode == "corporate" else mode
        self.original_mode = mode  # –°–æ—Ö—Ä–∞–Ω—è–µ–º –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω–æ–µ –Ω–∞–∑–≤–∞–Ω–∏–µ
        self.model = model

        # –î–ª—è –æ–±—Ä–∞—Ç–Ω–æ–π —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏ —Å–æ —Å—Ç–∞—Ä—ã–º –∫–æ–¥–æ–º
        self.ollama_url = ollama_url or settings.EMBEDDINGS_BASEURL
        self.hub_url = hub_url or settings.CORPORATE_API_URL
        self.keycloak_token = keycloak_token or settings.CORPORATE_API_TOKEN
        self.system_user = system_user or settings.CORPORATE_API_USERNAME

        logger.info(
            f"üöÄ EmbeddingsManager initialized: mode={self.original_mode} "
            f"(internal: {self.mode}), model={self.model}"
        )

    def switch_mode(self, mode: str):
        """
        –ü–µ—Ä–µ–∫–ª—é—á–∏—Ç—å —Ä–µ–∂–∏–º —Ä–∞–±–æ—Ç—ã

        Args:
            mode: –ù–æ–≤—ã–π —Ä–µ–∂–∏–º ('local' –∏–ª–∏ 'corporate')
        """
        if mode not in ["local", "corporate", "aihub"]:
            raise ValueError(f"Incorrect mode: must be 'local' or 'corporate', got '{mode}'")

        self.original_mode = mode
        self.mode = "aihub" if mode == "corporate" else mode
        logger.info(f"üîÑ Switched embeddings mode to: {self.original_mode} (internal: {self.mode})")

    def switch_model(self, model: str):
        """–ü–µ—Ä–µ–∫–ª—é—á–∏—Ç—å –º–æ–¥–µ–ª—å"""
        self.model = model
        logger.info(f"üîÑ Switched embeddings model to: {model}")

    def update_token(self, keycloak_token: str):
        """–û–±–Ω–æ–≤–∏—Ç—å —Ç–æ–∫–µ–Ω (–¥–ª—è –æ–±—Ä–∞—Ç–Ω–æ–π —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏)"""
        self.keycloak_token = keycloak_token
        logger.info("üîë Updated Keycloak token")

    async def get_available_models(self) -> List[str]:
        """–ü–æ–ª—É—á–∏—Ç—å —Å–ø–∏—Å–æ–∫ –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π"""
        try:
            models = await llm_manager.get_available_models(source=self.mode)
            logger.info(f"üìã Available models for {self.original_mode}: {models}")
            return models
        except Exception as e:
            logger.error(f"‚ùå Failed to get available models: {e}")
            return []

    def get_embedding_dimension(self) -> int:
        """
        –ü–æ–ª—É—á–∏—Ç—å –æ–∂–∏–¥–∞–µ–º—É—é —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤ –¥–ª—è —Ç–µ–∫—É—â–µ–≥–æ —Ä–µ–∂–∏–º–∞

        Returns:
            –†–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å –≤–µ–∫—Ç–æ—Ä–∞ —ç–º–±–µ–¥–¥–∏–Ω–≥–∞
        """
        return self.DEFAULT_DIMENSIONS.get(self.mode, 1024)

    def embedd_documents(self, texts: List[str]) -> List[List[float]]:
        """
        –ü–æ–ª—É—á–∏—Ç—å —ç–º–±–µ–¥–¥–∏–Ω–≥–∏ –¥–ª—è —Å–ø–∏—Å–∫–∞ —Ç–µ–∫—Å—Ç–æ–≤ (—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–∞—è –≤–µ—Ä—Å–∏—è –¥–ª—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏)

        Args:
            texts: –°–ø–∏—Å–æ–∫ —Ç–µ–∫—Å—Ç–æ–≤ –¥–ª—è —ç–º–±–µ–¥–¥–∏–Ω–≥–∞

        Returns:
            List[List[float]]: –°–ø–∏—Å–æ–∫ –≤–µ–∫—Ç–æ—Ä–æ–≤ —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤
        """
        import asyncio

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –µ—Å—Ç—å –ª–∏ —É–∂–µ running event loop
        try:
            loop = asyncio.get_running_loop()
        except RuntimeError:
            # –ù–µ—Ç running loop - —Å–æ–∑–¥–∞–µ–º –Ω–æ–≤—ã–π
            return asyncio.run(self.embedd_documents_async(texts))
        else:
            # –ï—Å—Ç—å running loop - –∏—Å–ø–æ–ª—å–∑—É–µ–º nest_asyncio
            logger.warning("‚ö†Ô∏è embedd_documents called from async context, consider using embedd_documents_async")
            try:
                import nest_asyncio
                nest_asyncio.apply()
            except ImportError:
                logger.error("‚ùå nest_asyncio not installed, cannot run async code from sync context")
                raise RuntimeError("Please install nest_asyncio or use embedd_documents_async")
            return asyncio.run(self.embedd_documents_async(texts))

    async def embedd_documents_async(self, texts: List[str]) -> List[List[float]]:
        """
        –ü–æ–ª—É—á–∏—Ç—å —ç–º–±–µ–¥–¥–∏–Ω–≥–∏ –¥–ª—è —Å–ø–∏—Å–∫–∞ —Ç–µ–∫—Å—Ç–æ–≤ (–∞—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–∞—è –≤–µ—Ä—Å–∏—è)

        Args:
            texts: –°–ø–∏—Å–æ–∫ —Ç–µ–∫—Å—Ç–æ–≤ –¥–ª—è —ç–º–±–µ–¥–¥–∏–Ω–≥–∞

        Returns:
            List[List[float]]: –°–ø–∏—Å–æ–∫ –≤–µ–∫—Ç–æ—Ä–æ–≤ —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤
        """
        if not texts:
            logger.warning("‚ö†Ô∏è Empty texts list provided")
            return []

        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –º–æ–¥–µ–ª—å –¥–ª—è —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤
        # –î–ª—è AI HUB –≤—Å–µ–≥–¥–∞ –∏—Å–ø–æ–ª—å–∑—É–µ–º "arctic", –¥–ª—è –æ—Å—Ç–∞–ª—å–Ω—ã—Ö - —Ç–µ–∫—É—â—É—é –º–æ–¥–µ–ª—å
        embedding_model = "arctic" if self.mode == "aihub" else self.model
        expected_dim = self.get_embedding_dimension()

        logger.info(
            f"üîÆ Generating embeddings for {len(texts)} texts using {self.original_mode}, "
            f"model: {embedding_model}, expected dimension: {expected_dim}"
        )

        all_embeddings = []

        for idx, text in enumerate(texts):
            try:
                logger.debug(f"üîå Requesting embedding {idx+1}/{len(texts)} ({len(text)} chars)")

                # –ò—Å–ø–æ–ª—å–∑—É–µ–º –Ω–æ–≤—É—é –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—É –ø—Ä–æ–≤–∞–π–¥–µ—Ä–æ–≤
                embedding = await llm_manager.generate_embedding(
                    text=text,
                    model_source=self.mode,  # –ò—Å–ø–æ–ª—å–∑—É–µ–º –≤–Ω—É—Ç—Ä–µ–Ω–Ω–µ–µ –∏–º—è (aihub)
                    model_name=embedding_model  # –î–ª—è aihub –≤—Å–µ–≥–¥–∞ "arctic"
                )

                if not embedding or len(embedding) == 0:
                    logger.error(f"‚ùå Empty embedding returned for text {idx+1}")
                    raise RuntimeError(f"Empty embedding returned for text {idx+1}")

                # –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç–∏
                actual_dim = len(embedding)
                if actual_dim != expected_dim:
                    logger.warning(
                        f"‚ö†Ô∏è Unexpected embedding dimension: expected {expected_dim}, "
                        f"got {actual_dim} for text {idx+1}"
                    )

                all_embeddings.append(embedding)
                logger.debug(f"‚úÖ Embedding {idx+1} received: {actual_dim} dimensions")

            except Exception as e:
                logger.error(f"‚ùå Failed to generate embedding for text {idx+1}: {e}")
                raise RuntimeError(f"Embedding generation failed for text {idx+1}: {e}")

        logger.info(
            f"‚úÖ Generated {len(all_embeddings)} embeddings successfully "
            f"(dimension: {len(all_embeddings[0]) if all_embeddings else 'N/A'})"
        )
        return all_embeddings


# Singleton instance
embeddings_manager = EmbeddingsManager()
